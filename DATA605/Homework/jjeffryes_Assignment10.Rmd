---
title: "Data 605 - Assignment 10"
author: "Jai Jeffryes"
date: "4/3/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Smith is in jail
I got this one! The whole thing. Yay.

Smith is in jail and has 1 dollar; he can get out on bail if he has 8 dollars.
A guard agrees to make a series of bets with him. If Smith bets A dollars, he wins A dollars with probability .4 and loses A dollars with probability .6.
Find the probability that he wins 8 dollars before losing all of his money if

(a) he bets 1 dollar each time (timid strategy).
(b) he bets, each time, as much as possible but not more than necessary to bring his fortune up to 8 dollars (bold strategy).
(c) Which strategy gives Smith the better chance of getting out of jail?

### Part 1, \$1
```{r}
library(markovchain)
library(diagram)
library(expm)
library(pracma)

# State space
Wallet1 <- c(as.character(0:8))

# Transition matrix
BetTransition1 <- matrix(c(
    1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
    0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
    0.0, 0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.6, 0.0, 0.4, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4, 0.0,
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4,
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0
	), nrow = 9, byrow = T)
dimnames(BetTransition1) <- list(Wallet1, Wallet1)

# Use the markovchain function to create a markovchain object
McWallet1 <- new("markovchain", states = Wallet1, byrow = T,
			  transitionMatrix = BetTransition1, name = "Jail Bet")
# Calling the object gives the transition matrix.
McWallet1

# That article I found for my discussion post had a diagram for transition
# matrices. Here's a so-so rendering. The arrows go the wrong direction.(?)
plotmat(BetTransition1, pos = c(5,4), box.size = 0.05, arr.length = 0.1)
```

Since losing all or winning $8 are end states, this is an absorbing Markov chain. I would like to see how that looks in canonical form.

```{r}
# State space
Wallet2 <- as.character(c(1:7, 0, 8))

# Transition matrix
BetTransition2 <- matrix(c(
    0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0,
    0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
    0.0, 0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.6, 0.0, 0.4, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.4,
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0
	), nrow = 9, byrow = T)
dimnames(BetTransition2) <- list(Wallet2, Wallet2)

# Use the markovchain function to create a markovchain object
McWallet2 <- new("markovchain", states = Wallet2, byrow = T,
			  transitionMatrix = BetTransition2, name = "Jail Bet")
# Calling the object gives the transition matrix.
McWallet2

```

#### The two forms compute identically
```{r}
# Canonical
BetTransition2%^%1000

# Original
BetTransition1%^%1000
```

**ANSWER**

We want to know, if Smith starts with \$1, what is the probability he'll reach \$8? Read off the transition probability for state 1 to state 8, $S_{18}$. **0.02030135**

**NOTE**

Further down I did some supplemental programming and computed descriptive values for Markov chains. I learned there that computing $B$, cf. p. 422, gives me the probabilities of absorption directly without having to guess how large an $N$ is needed.

### Part B, bold bets
The last computation worked out. It's all on the question, do I set up the transition matrix correctly? It's a programming assignment. Express the algorithm in a matrix. I get nervous about matrices, but when I set them up correctly, they turn out to be elegant programming solutions.

Now keep your head straight. He starts out with \$1, and that's what he can bet. If he has more money, he can bet all of it.

```{r}
# State space
Wallet1 <- c(as.character(0:8))

# Transition matrix
BetTransition1 <- matrix(c(
    1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, # 0
    0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, # 1
    0.6, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, # 2
    0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, # 3
    0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, # 4
    0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, # 5
    0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.4, # 6
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4, # 7
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0  # 8
	), nrow = 9, byrow = T)
dimnames(BetTransition1) <- list(Wallet1, Wallet1)

# Use the markovchain function to create a markovchain object
McWallet1 <- new("markovchain", states = Wallet1, byrow = T,
			  transitionMatrix = BetTransition1, name = "Jail Bet")
# Calling the object gives the transition matrix.
McWallet1

BetTransition1%^%1000
```

**ANSWER**: The probability that Smith can start with \$1, bet boldly and get out of jail is in the transition matrix at $S_{18}$. **0.064**

### Part C, comparision
The probabilities for Smith getting out of jail are:

- Timid strategy: 0.02030135
- Bold strategy: 0.064

At 6.4%, Smith has about three times the chance of getting out of jail if he takes the bold strategy.

### Supplement
Those are the answers, but I would like to apprehend a couple other niceties.

#### Fundamental matrix
Since I put the first problem into canonical form, I can come up with its Fundamental matrix.

```{r}
BetTransition2
r <- 7 # transient states
Q <- BetTransition2[1:r, 1:r]

# inverse of I - Q
N <- inv(diag(r) - Q)
N
max(N)
```

That gives the expected number of times that the process is in the transient state before being absorbed. 
Theorem 11.5 computes the expected number of steps before the chain is absorbed.

```{r}
c <- matrix(rep(1, 7), nrow = 7, byrow = T)
t <- N %*% c
t
```

#### Computation
```{r}
AbsorbingChain <- function(P, transient){
	# Assumptions:
	# P is a transition matrix in canonical form.
	Q <- P[1:transient, 1:transient]
	R <- P[1:transient, -(1:transient)]
	N <- inv(diag(transient) - Q)
	c <- matrix(rep(1, transient), nrow = transient, byrow = T)
	t <- N %*% c
	B <- N %*% R

	print("P:")
	print(P)	
	print("Q:")
	print(Q)
	print("R:")
	print(R)
	print("N:")
	print(N)
	print("t:")
	print(t)
	print("B:")
	print(B)
}

# Try it out on Drunkard's Walk
# Canonical form
DrunkState_canon <- as.character(c(1:3, 0, 4))
DrunkTransition_canon <- matrix(c(
	0.0, 0.5, 0.0, 0.5, 0.0,
	0.5, 0.0, 0.5, 0.0, 0.0,
	0.0, 0.5, 0.0, 0.0, 0.5,
	0.0, 0.0, 0.0, 1.0, 0.0,
	0.0, 0.0, 0.0, 0.0, 1.0
), nrow = 5, byrow = T)
dimnames(DrunkTransition_canon) <- list(DrunkState_canon, DrunkState_canon)

AbsorbingChain(DrunkTransition_canon, 3)
```

Those all work out the same as in the book, p422-3. Let's try it for part A.

The output of $B$ gives me the answer that I was looking for in Parts A and B when I calculated the transition matrixes up to an arbitrarily high $N$.

```{r}
AbsorbingChain(BetTransition2, 7)
```

